{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('us-states.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = {\n",
    "    'Alabama' : 95,\n",
    "    'Alaska' : 1,\n",
    "    'American Samoa' : 721,\n",
    "    'Arizona' : 60,\n",
    "    'Arkansas' : 57,\n",
    "    'California' : 251,\n",
    "    'Colorado' : 52,\n",
    "    'Connecticut' : 741,\n",
    "    'Delaware' : 485,\n",
    "    'District of Columbia' : 11011,\n",
    "    'Florida' : 378,\n",
    "    'Georgia' : 177,\n",
    "    'Guam' : 808,\n",
    "    'Hawaii' : 222,\n",
    "    'Idaho' : 20,\n",
    "    'Illinois' : 231,\n",
    "    'Indiana' : 184,\n",
    "    'Iowa' : 55,\n",
    "    'Kansas' : 36,\n",
    "    'Kentucky' : 112,\n",
    "    'Louisiana' : 108,\n",
    "    'Maine' : 43,\n",
    "    'Maryland' : 618,\n",
    "    'Massachusetts' : 871,\n",
    "    'Michigan' : 175,\n",
    "    'Minnesota' : 68,\n",
    "    'Mississippi' : 63,\n",
    "    'Missouri' : 88,\n",
    "    'Montana' : 7,\n",
    "    'Nebraska' : 24,\n",
    "    'Nevada' : 26,\n",
    "    'New Hampshire' : 148,\n",
    "    'New Jersey' : 1218,\n",
    "    'New Mexico' : 17,\n",
    "    'New York' : 420,\n",
    "    'North Carolina' : 206,\n",
    "    'North Dakota' : 10,\n",
    "    'Northern Mariana Islands' : 307,\n",
    "    'Ohio' : 284,\n",
    "    'Oklahoma' : 57,\n",
    "    'Oregon' : 41,\n",
    "    'Pennsylvania' : 286,\n",
    "    'Puerto Rico' : 1046,\n",
    "    'Rhode Island' : 1021,\n",
    "    'South Carolina' : 162,\n",
    "    'South Dakota' : 11,\n",
    "    'Tennessee' : 160,\n",
    "    'Texas' : 105,\n",
    "    'Utah' : 36,\n",
    "    'Vermont' : 67,\n",
    "    'Virgin Islands' : 799,\n",
    "    'Virginia' : 212,\n",
    "    'Washington' : 107,\n",
    "    'West Virginia' : 76,\n",
    "    'Wisconsin' : 106,\n",
    "    'Wyoming' : 6\n",
    "}\n",
    "\n",
    "age = {\n",
    "    'Alabama' : 39.2,\n",
    "    'Alaska' : 34.6,\n",
    "    'American Samoa' : 25.5,\n",
    "    'Arizona' : 37.9,\n",
    "    'Arkansas' : 38.3,\n",
    "    'California' : 36.8,\n",
    "    'Colorado' : 36.9,\n",
    "    'Connecticut' : 41.0,\n",
    "    'Delaware' : 40.7,\n",
    "    'District of Columbia' : 34.0,\n",
    "    'Florida' : 42.2,\n",
    "    'Georgia' : 36.9,\n",
    "    'Guam' : 29.0,\n",
    "    'Hawaii' : 39.2,\n",
    "    'Idaho' : 36.6,\n",
    "    'Illinois' : 38.3,\n",
    "    'Indiana' : 37.9,\n",
    "    'Iowa' : 38.2,\n",
    "    'Kansas' : 36.9,\n",
    "    'Kentucky' : 38.9,\n",
    "    'Louisiana' : 37.2,\n",
    "    'Maine' : 44.9,\n",
    "    'Maryland' : 38.8,\n",
    "    'Massachusetts' : 39.4,\n",
    "    'Michigan' : 39.8,\n",
    "    'Minnesota' : 38.1,\n",
    "    'Mississippi' : 37.7,\n",
    "    'Missouri' : 38.7,\n",
    "    'Montana' : 39.9,\n",
    "    'Nebraska' : 36.6,\n",
    "    'Nevada' : 38.1,\n",
    "    'New Hampshire' : 43.0,\n",
    "    'New Jersey' : 40.0,\n",
    "    'New Mexico' : 38.1,\n",
    "    'New York' : 39.0,\n",
    "    'North Carolina' : 38.9,\n",
    "    'North Dakota' : 35.2,\n",
    "    'Northern Mariana Islands' : 33.6,\n",
    "    'Ohio' : 39.4,\n",
    "    'Oklahoma' : 36.7,\n",
    "    'Oregon' : 39.4,\n",
    "    'Pennsylvania' : 40.8,\n",
    "    'Puerto Rico' : 41.5,\n",
    "    'Rhode Island' : 40.1,\n",
    "    'South Carolina' : 39.6,\n",
    "    'South Dakota' : 37.1,\n",
    "    'Tennessee' : 38.8,\n",
    "    'Texas' : 34.8,\n",
    "    'Utah' : 31.0,\n",
    "    'Vermont' : 42.8,\n",
    "    'Virgin Islands' : 41.0,\n",
    "    'Virginia' : 38.4,\n",
    "    'Washington' : 37.7,\n",
    "    'West Virginia' : 42.7,\n",
    "    'Wisconsin' : 39.6,\n",
    "    'Wyoming' : 38.0\n",
    "}\n",
    "\n",
    "gdpPerCap = {\n",
    "    'Alabama' : 45219,\n",
    "    'Alaska' : 73205,\n",
    "    'American Samoa' : 11467,\n",
    "    'Arizona' : 48055,\n",
    "    'Arkansas' : 42454,\n",
    "    'California' : 74205,\n",
    "    'Colorado' : 63882,\n",
    "    'Connecticut' : 76342,\n",
    "    'Delaware' : 77253,\n",
    "    'District of Columbia' : 200277,\n",
    "    'Florida' : 48318,\n",
    "    'Georgia' : 55832,\n",
    "    'Guam' : 35713,\n",
    "    'Hawaii' : 64096,\n",
    "    'Idaho' : 43430,\n",
    "    'Illinois' : 67268,\n",
    "    'Indiana' : 55172,\n",
    "    'Iowa' : 59977,\n",
    "    'Kansas' : 56334,\n",
    "    'Kentucky' : 36898,\n",
    "    'Louisiana' : 53589,\n",
    "    'Maine' : 47969,\n",
    "    'Maryland' : 68573,\n",
    "    'Massachusetts' : 82480,\n",
    "    'Michigan' : 53209,\n",
    "    'Minnesota' : 64675,\n",
    "    'Mississippi' : 37948,\n",
    "    'Missouri' : 51699,\n",
    "    'Montana' : 46609,\n",
    "    'Nebraska' : 63942,\n",
    "    'Nevada' : 55269,\n",
    "    'New Hampshire' : 63067,\n",
    "    'New Jersey' : 69378,\n",
    "    'New Mexico' : 46954,\n",
    "    'New York' : 85746,\n",
    "    'North Carolina' : 54441,\n",
    "    'North Dakota' : 72597,\n",
    "    'Northern Mariana Islands' : 23259,\n",
    "    'Ohio' : 57492,\n",
    "    'Oklahoma' : 50613,\n",
    "    'Oregon' : 56956,\n",
    "    'Pennsylvania' : 61594,\n",
    "    'Puerto Rico' : 31651,\n",
    "    'Rhode Island' : 57852,\n",
    "    'South Carolina' : 45280,\n",
    "    'South Dakota' : 58624,\n",
    "    'Tennessee' : 53933,\n",
    "    'Texas' : 61167,\n",
    "    'Utah' : 55550,\n",
    "    'Vermont' : 53523,\n",
    "    'Virgin Islands' : 35938,\n",
    "    'Virginia' : 62563,\n",
    "    'Washington' : 74182,\n",
    "    'West Virginia' : 43053,\n",
    "    'Wisconsin' : 57720,\n",
    "    'Wyoming' : 69900\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seriesCreator(dataDict):\n",
    "    seriesDict = pd.Series(dataDict)\n",
    "    dataList = []\n",
    "    for x in range (0, 2889):\n",
    "        dataList.append(seriesDict[data['state'].iloc[x]])\n",
    "    return pd.Series(dataList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "denseSeries = seriesCreator(dense)\n",
    "ageSeries = seriesCreator(age)\n",
    "gdpSeries = seriesCreator(gdpPerCap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seriesConcat(series):\n",
    "    return pd.concat([data, series.reindex(data.index)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = seriesConcat(denseSeries)\n",
    "data = seriesConcat(ageSeries)\n",
    "data = seriesConcat(gdpSeries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['date', 'state', 'fips', 'cases', 'deaths', 'pop_density', 'avg_age', 'gdp_per_capita']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>fips</th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "      <th>pop_density</th>\n",
       "      <th>avg_age</th>\n",
       "      <th>gdp_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>Washington</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>37.7</td>\n",
       "      <td>74182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Washington</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>37.7</td>\n",
       "      <td>74182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>Washington</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>37.7</td>\n",
       "      <td>74182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>231</td>\n",
       "      <td>38.3</td>\n",
       "      <td>67268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>Washington</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>37.7</td>\n",
       "      <td>74182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2884</th>\n",
       "      <td>2020-04-23</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>51</td>\n",
       "      <td>11000</td>\n",
       "      <td>375</td>\n",
       "      <td>212</td>\n",
       "      <td>38.4</td>\n",
       "      <td>62563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885</th>\n",
       "      <td>2020-04-23</td>\n",
       "      <td>Washington</td>\n",
       "      <td>53</td>\n",
       "      <td>12906</td>\n",
       "      <td>717</td>\n",
       "      <td>107</td>\n",
       "      <td>37.7</td>\n",
       "      <td>74182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>2020-04-23</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>54</td>\n",
       "      <td>981</td>\n",
       "      <td>31</td>\n",
       "      <td>76</td>\n",
       "      <td>42.7</td>\n",
       "      <td>43053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>2020-04-23</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>55</td>\n",
       "      <td>5052</td>\n",
       "      <td>257</td>\n",
       "      <td>106</td>\n",
       "      <td>39.6</td>\n",
       "      <td>57720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>2020-04-23</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56</td>\n",
       "      <td>332</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>38.0</td>\n",
       "      <td>69900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2889 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date          state  fips  cases  deaths  pop_density  avg_age  \\\n",
       "0     2020-01-21     Washington    53      1       0          107     37.7   \n",
       "1     2020-01-22     Washington    53      1       0          107     37.7   \n",
       "2     2020-01-23     Washington    53      1       0          107     37.7   \n",
       "3     2020-01-24       Illinois    17      1       0          231     38.3   \n",
       "4     2020-01-24     Washington    53      1       0          107     37.7   \n",
       "...          ...            ...   ...    ...     ...          ...      ...   \n",
       "2884  2020-04-23       Virginia    51  11000     375          212     38.4   \n",
       "2885  2020-04-23     Washington    53  12906     717          107     37.7   \n",
       "2886  2020-04-23  West Virginia    54    981      31           76     42.7   \n",
       "2887  2020-04-23      Wisconsin    55   5052     257          106     39.6   \n",
       "2888  2020-04-23        Wyoming    56    332       7            6     38.0   \n",
       "\n",
       "      gdp_per_capita  \n",
       "0              74182  \n",
       "1              74182  \n",
       "2              74182  \n",
       "3              67268  \n",
       "4              74182  \n",
       "...              ...  \n",
       "2884           62563  \n",
       "2885           74182  \n",
       "2886           43053  \n",
       "2887           57720  \n",
       "2888           69900  \n",
       "\n",
       "[2889 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>fips</th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "      <th>pop_density</th>\n",
       "      <th>avg_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>Washington</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>37.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Washington</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>37.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>Washington</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>37.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>231</td>\n",
       "      <td>38.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>Washington</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>37.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       state  fips  cases  deaths  pop_density  avg_age\n",
       "0  2020-01-21  Washington    53      1       0          107     37.7\n",
       "1  2020-01-22  Washington    53      1       0          107     37.7\n",
       "2  2020-01-23  Washington    53      1       0          107     37.7\n",
       "3  2020-01-24    Illinois    17      1       0          231     38.3\n",
       "4  2020-01-24  Washington    53      1       0          107     37.7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2889, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#label encoder for dates\n",
    "def scrub_date(date1):\n",
    "    date_parts = date1.split('-')\n",
    "    f_date = dt.date(int(date_parts[0]), int(date_parts[1]), int(date_parts[2]))\n",
    "    delta = f_date - dt.date(2020, 1, 21)\n",
    "    return delta.days\n",
    "\n",
    "for i in range(len(data['date'])):\n",
    "    data['date'][i] = scrub_date(data['date'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/justin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "#label encoder for state\n",
    "id = 1\n",
    "state_dict = {}\n",
    "for i in range(len(data['state'])):\n",
    "    state = data['state'][i]\n",
    "    if state not in state_dict:\n",
    "        state_dict[state] = id\n",
    "        id += 1\n",
    "        data['state'][i] = state_dict[state]\n",
    "    else:\n",
    "        data['state'][i] = state_dict[state]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('fips', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.cases\n",
    "X = data.drop('cases', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "      <th>pop_density</th>\n",
       "      <th>avg_age</th>\n",
       "      <th>gdp_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>37.7</td>\n",
       "      <td>74182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>37.7</td>\n",
       "      <td>74182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>37.7</td>\n",
       "      <td>74182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>231</td>\n",
       "      <td>38.3</td>\n",
       "      <td>67268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>37.7</td>\n",
       "      <td>74182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2884</th>\n",
       "      <td>93</td>\n",
       "      <td>33</td>\n",
       "      <td>11000</td>\n",
       "      <td>375</td>\n",
       "      <td>212</td>\n",
       "      <td>38.4</td>\n",
       "      <td>62563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885</th>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>12906</td>\n",
       "      <td>717</td>\n",
       "      <td>107</td>\n",
       "      <td>37.7</td>\n",
       "      <td>74182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>93</td>\n",
       "      <td>54</td>\n",
       "      <td>981</td>\n",
       "      <td>31</td>\n",
       "      <td>76</td>\n",
       "      <td>42.7</td>\n",
       "      <td>43053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>93</td>\n",
       "      <td>6</td>\n",
       "      <td>5052</td>\n",
       "      <td>257</td>\n",
       "      <td>106</td>\n",
       "      <td>39.6</td>\n",
       "      <td>57720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>93</td>\n",
       "      <td>45</td>\n",
       "      <td>332</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>38.0</td>\n",
       "      <td>69900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2889 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     date state  cases  deaths  pop_density  avg_age  gdp_per_capita\n",
       "0       0     1      1       0          107     37.7           74182\n",
       "1       1     1      1       0          107     37.7           74182\n",
       "2       2     1      1       0          107     37.7           74182\n",
       "3       3     2      1       0          231     38.3           67268\n",
       "4       3     1      1       0          107     37.7           74182\n",
       "...   ...   ...    ...     ...          ...      ...             ...\n",
       "2884   93    33  11000     375          212     38.4           62563\n",
       "2885   93     1  12906     717          107     37.7           74182\n",
       "2886   93    54    981      31           76     42.7           43053\n",
       "2887   93     6   5052     257          106     39.6           57720\n",
       "2888   93    45    332       7            6     38.0           69900\n",
       "\n",
       "[2889 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators = 100, random_state = 1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mae = mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338.02921161825725"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "      <th>pop_density</th>\n",
       "      <th>avg_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2889.000000</td>\n",
       "      <td>2889.00000</td>\n",
       "      <td>2889.000000</td>\n",
       "      <td>2889.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4734.918311</td>\n",
       "      <td>190.28972</td>\n",
       "      <td>420.761855</td>\n",
       "      <td>38.263621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18762.852274</td>\n",
       "      <td>967.45956</td>\n",
       "      <td>1407.884868</td>\n",
       "      <td>2.755086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>36.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>365.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>38.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2331.000000</td>\n",
       "      <td>63.00000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>39.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>263460.000000</td>\n",
       "      <td>15740.00000</td>\n",
       "      <td>11011.000000</td>\n",
       "      <td>44.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cases       deaths   pop_density      avg_age\n",
       "count    2889.000000   2889.00000   2889.000000  2889.000000\n",
       "mean     4734.918311    190.28972    420.761855    38.263621\n",
       "std     18762.852274    967.45956   1407.884868     2.755086\n",
       "min         0.000000      0.00000      1.000000    25.500000\n",
       "25%        19.000000      0.00000     55.000000    36.900000\n",
       "50%       365.000000      6.00000    108.000000    38.300000\n",
       "75%      2331.000000     63.00000    284.000000    39.600000\n",
       "max    263460.000000  15740.00000  11011.000000    44.900000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                448       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "distribution_lambda (Distrib ((None, 64), (None, 64))  0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 8,833\n",
      "Trainable params: 8,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_tf_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(64, activation = 'relu', input_shape=[len(X_train.keys())]),\n",
    "        layers.Dense(64, activation = 'relu'),\n",
    "        layers.Dense(64, activation = 'relu'),\n",
    "        tfp.layers.DistributionLambda(lambda t: tfd.Normal(loc=t, scale=1)),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    #optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "    \n",
    "    model.compile(loss = 'mse', optimizer = optimizer, metrics = ['mae', 'mse'])\n",
    "    \n",
    "    return model \n",
    "\n",
    "tf_model = build_tf_model()\n",
    "\n",
    "tf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2166 samples\n",
      "Epoch 1/20\n",
      "2166/2166 [==============================] - 1s 246us/sample - loss: 355402189.1413 - mae: 4768.2344 - mse: 355402144.0000\n",
      "Epoch 2/20\n",
      "2166/2166 [==============================] - 0s 209us/sample - loss: 169385242.2899 - mae: 3682.4856 - mse: 169385296.0000\n",
      "Epoch 3/20\n",
      "2166/2166 [==============================] - 0s 185us/sample - loss: 16755152.0794 - mae: 1753.3740 - mse: 16755155.0000\n",
      "Epoch 4/20\n",
      "2166/2166 [==============================] - 0s 137us/sample - loss: 13322258.4582 - mae: 1156.8405 - mse: 13322260.0000\n",
      "Epoch 5/20\n",
      "2166/2166 [==============================] - 0s 193us/sample - loss: 13252079.5210 - mae: 1146.5488 - mse: 13252079.0000\n",
      "Epoch 6/20\n",
      "2166/2166 [==============================] - 0s 162us/sample - loss: 13762134.7913 - mae: 1174.1606 - mse: 13762133.0000\n",
      "Epoch 7/20\n",
      "2166/2166 [==============================] - 0s 163us/sample - loss: 13309639.3952 - mae: 1121.4305 - mse: 13309640.0000\n",
      "Epoch 8/20\n",
      "2166/2166 [==============================] - 0s 158us/sample - loss: 12807374.4014 - mae: 1124.9111 - mse: 12807373.0000\n",
      "Epoch 9/20\n",
      "2166/2166 [==============================] - 0s 130us/sample - loss: 13207422.6994 - mae: 1108.6188 - mse: 13207422.0000\n",
      "Epoch 10/20\n",
      "2166/2166 [==============================] - 0s 132us/sample - loss: 13697815.9806 - mae: 1171.6177 - mse: 13697818.0000\n",
      "Epoch 11/20\n",
      "2166/2166 [==============================] - 0s 149us/sample - loss: 13668532.0851 - mae: 1158.8416 - mse: 13668531.0000\n",
      "Epoch 12/20\n",
      "2166/2166 [==============================] - 0s 155us/sample - loss: 13092843.8586 - mae: 1111.8345 - mse: 13092842.0000\n",
      "Epoch 13/20\n",
      "2166/2166 [==============================] - 0s 216us/sample - loss: 12686940.9321 - mae: 1088.2855 - mse: 12686942.0000\n",
      "Epoch 14/20\n",
      "2166/2166 [==============================] - 1s 234us/sample - loss: 12959596.8654 - mae: 1109.0784 - mse: 12959599.0000\n",
      "Epoch 15/20\n",
      "2166/2166 [==============================] - 0s 163us/sample - loss: 12684815.0771 - mae: 1103.6460 - mse: 12684816.0000\n",
      "Epoch 16/20\n",
      "2166/2166 [==============================] - 0s 135us/sample - loss: 12673908.4126 - mae: 1103.0116 - mse: 12673906.0000\n",
      "Epoch 17/20\n",
      "2166/2166 [==============================] - 0s 194us/sample - loss: 12527832.3861 - mae: 1086.8074 - mse: 12527832.0000\n",
      "Epoch 18/20\n",
      "2166/2166 [==============================] - 0s 165us/sample - loss: 12309887.3790 - mae: 1066.5216 - mse: 12309887.0000\n",
      "Epoch 19/20\n",
      "2166/2166 [==============================] - 0s 163us/sample - loss: 12738308.8299 - mae: 1114.6735 - mse: 12738308.0000\n",
      "Epoch 20/20\n",
      "2166/2166 [==============================] - 0s 166us/sample - loss: 12326393.9010 - mae: 1092.6893 - mse: 12326395.0000\n"
     ]
    }
   ],
   "source": [
    "history = tf_model.fit(X_train, y_train, epochs = 20, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.554022e+08</td>\n",
       "      <td>4768.234375</td>\n",
       "      <td>355402144.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.693852e+08</td>\n",
       "      <td>3682.485596</td>\n",
       "      <td>169385296.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.675515e+07</td>\n",
       "      <td>1753.374023</td>\n",
       "      <td>16755155.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.332226e+07</td>\n",
       "      <td>1156.840454</td>\n",
       "      <td>13322260.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.325208e+07</td>\n",
       "      <td>1146.548828</td>\n",
       "      <td>13252079.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           loss          mae          mse  epoch\n",
       "0  3.554022e+08  4768.234375  355402144.0      0\n",
       "1  1.693852e+08  3682.485596  169385296.0      1\n",
       "2  1.675515e+07  1753.374023   16755155.0      2\n",
       "3  1.332226e+07  1156.840454   13322260.0      3\n",
       "4  1.325208e+07  1146.548828   13252079.0      4"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe75f4ca290>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(hist['epoch'], hist['loss'], label = 'Loss')\n",
    "plt.plot(hist['epoch'], hist['mae'], label = 'MAE')\n",
    "plt.plot(hist['epoch'], hist['mse'], label = 'MSE')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2166 samples\n",
      "Epoch 1/1000\n",
      "2166/2166 [==============================] - 1s 288us/sample - loss: 345254109.4294 - mae: 6948.8931 - mse: 345254112.0000\n",
      "Epoch 2/1000\n",
      "2166/2166 [==============================] - 0s 162us/sample - loss: 337155329.9797 - mae: 6599.0708 - mse: 337155328.0000\n",
      "Epoch 3/1000\n",
      "2166/2166 [==============================] - 0s 222us/sample - loss: 323684844.9714 - mae: 6708.4390 - mse: 323684896.0000\n",
      "Epoch 4/1000\n",
      "2166/2166 [==============================] - 0s 159us/sample - loss: 294139637.6288 - mae: 6465.6602 - mse: 294139648.0000\n",
      "Epoch 5/1000\n",
      "2166/2166 [==============================] - 0s 170us/sample - loss: 239965355.7193 - mae: 6276.0508 - mse: 239965360.0000\n",
      "Epoch 6/1000\n",
      "2166/2166 [==============================] - 0s 167us/sample - loss: 145304162.5716 - mae: 5285.8711 - mse: 145304144.0000\n",
      "Epoch 7/1000\n",
      "2166/2166 [==============================] - 0s 144us/sample - loss: 53400983.0065 - mae: 3694.8865 - mse: 53400976.0000\n",
      "Epoch 8/1000\n",
      "2166/2166 [==============================] - 1s 256us/sample - loss: 22736262.7673 - mae: 2600.8540 - mse: 22736258.0000\n",
      "Epoch 9/1000\n",
      "2166/2166 [==============================] - 0s 180us/sample - loss: 16189714.8412 - mae: 2140.4714 - mse: 16189714.0000\n",
      "Epoch 10/1000\n",
      "2166/2166 [==============================] - 0s 163us/sample - loss: 17514889.7585 - mae: 2390.6091 - mse: 17514894.0000\n",
      "Epoch 11/1000\n",
      "2166/2166 [==============================] - 0s 159us/sample - loss: 17428192.1140 - mae: 2388.6831 - mse: 17428194.0000\n",
      "Epoch 12/1000\n",
      "2166/2166 [==============================] - 0s 166us/sample - loss: 14080055.3435 - mae: 1722.0736 - mse: 14080059.0000\n",
      "Epoch 13/1000\n",
      "2166/2166 [==============================] - 0s 151us/sample - loss: 15433575.1764 - mae: 2137.3901 - mse: 15433577.0000\n",
      "Epoch 14/1000\n",
      "2166/2166 [==============================] - 0s 159us/sample - loss: 16207135.0693 - mae: 2171.7410 - mse: 16207136.0000\n",
      "Epoch 15/1000\n",
      "2166/2166 [==============================] - 0s 172us/sample - loss: 15884934.5875 - mae: 2270.0342 - mse: 15884935.0000\n",
      "Epoch 16/1000\n",
      "2166/2166 [==============================] - 0s 142us/sample - loss: 15024203.0868 - mae: 1977.8606 - mse: 15024205.0000\n",
      "Epoch 17/1000\n",
      "2166/2166 [==============================] - 0s 174us/sample - loss: 15073278.5249 - mae: 2032.3197 - mse: 15073279.0000\n",
      "Epoch 18/1000\n",
      "2166/2166 [==============================] - 0s 154us/sample - loss: 16725518.8052 - mae: 2347.4741 - mse: 16725519.0000\n",
      "Epoch 19/1000\n",
      "2166/2166 [==============================] - 0s 186us/sample - loss: 14489383.5956 - mae: 1788.4097 - mse: 14489383.0000\n",
      "Epoch 20/1000\n",
      "2166/2166 [==============================] - 0s 185us/sample - loss: 13252235.5764 - mae: 1644.4689 - mse: 13252235.0000\n",
      "Epoch 21/1000\n",
      "2166/2166 [==============================] - 0s 186us/sample - loss: 15504623.6955 - mae: 1983.5780 - mse: 15504620.0000\n",
      "Epoch 22/1000\n",
      "2166/2166 [==============================] - 0s 183us/sample - loss: 16933780.0831 - mae: 2300.8726 - mse: 16933780.0000\n",
      "Epoch 23/1000\n",
      "2166/2166 [==============================] - 0s 178us/sample - loss: 14018573.4474 - mae: 1717.6141 - mse: 14018573.0000\n",
      "Epoch 24/1000\n",
      "2166/2166 [==============================] - 0s 194us/sample - loss: 13078062.9751 - mae: 1609.5619 - mse: 13078062.0000\n",
      "Epoch 25/1000\n",
      "2166/2166 [==============================] - 0s 178us/sample - loss: 14198577.3315 - mae: 1832.1946 - mse: 14198578.0000\n",
      "Epoch 26/1000\n",
      "2166/2166 [==============================] - 0s 160us/sample - loss: 13822128.4538 - mae: 1688.0315 - mse: 13822128.0000\n",
      "Epoch 27/1000\n",
      "2166/2166 [==============================] - 0s 195us/sample - loss: 13353489.8687 - mae: 1772.5399 - mse: 13353489.0000\n",
      "Epoch 28/1000\n",
      "2166/2166 [==============================] - 0s 230us/sample - loss: 14558546.4848 - mae: 1984.0886 - mse: 14558549.0000\n",
      "Epoch 29/1000\n",
      "2166/2166 [==============================] - 0s 222us/sample - loss: 13187940.2350 - mae: 1715.4341 - mse: 13187939.0000\n",
      "Epoch 30/1000\n",
      "2166/2166 [==============================] - 1s 303us/sample - loss: 15671305.7978 - mae: 2113.4897 - mse: 15671306.0000\n",
      "Epoch 31/1000\n",
      "2166/2166 [==============================] - 1s 252us/sample - loss: 15923986.8781 - mae: 2304.5020 - mse: 15923989.0000\n",
      "Epoch 32/1000\n",
      "2166/2166 [==============================] - 0s 175us/sample - loss: 14033686.0295 - mae: 1935.7849 - mse: 14033688.0000\n",
      "Epoch 33/1000\n",
      "2166/2166 [==============================] - 0s 145us/sample - loss: 12715896.6214 - mae: 1580.3401 - mse: 12715898.0000\n",
      "Epoch 34/1000\n",
      "2166/2166 [==============================] - 0s 118us/sample - loss: 16135537.5596 - mae: 2258.5107 - mse: 16135536.0000\n",
      "Epoch 35/1000\n",
      "2166/2166 [==============================] - 0s 157us/sample - loss: 16496363.3167 - mae: 2324.4226 - mse: 16496368.0000 - loss: 14164475.2500 - mae: 1914.4603 - mse: 1\n",
      "Epoch 36/1000\n",
      "2166/2166 [==============================] - 0s 201us/sample - loss: 15369242.0912 - mae: 2031.2468 - mse: 15369242.0000\n",
      "Epoch 37/1000\n",
      "2166/2166 [==============================] - 0s 145us/sample - loss: 13035685.7760 - mae: 1599.3593 - mse: 13035688.0000\n",
      "Epoch 38/1000\n",
      "2166/2166 [==============================] - 0s 174us/sample - loss: 15080626.2024 - mae: 2083.6099 - mse: 15080629.0000\n",
      "Epoch 39/1000\n",
      "2166/2166 [==============================] - 0s 186us/sample - loss: 13947298.2410 - mae: 1867.1869 - mse: 13947299.0000\n",
      "Epoch 40/1000\n",
      "2166/2166 [==============================] - 1s 285us/sample - loss: 15756342.3961 - mae: 2183.1021 - mse: 15756342.0000\n",
      "Epoch 41/1000\n",
      "2166/2166 [==============================] - 1s 232us/sample - loss: 14027977.0679 - mae: 1897.7963 - mse: 14027979.0000\n",
      "Epoch 42/1000\n",
      "2166/2166 [==============================] - 0s 173us/sample - loss: 14795808.0157 - mae: 2036.4130 - mse: 14795808.0000\n",
      "Epoch 43/1000\n",
      "2166/2166 [==============================] - 0s 164us/sample - loss: 13995143.5164 - mae: 1871.2972 - mse: 13995145.0000\n",
      "Epoch 44/1000\n",
      "2166/2166 [==============================] - 0s 135us/sample - loss: 14635821.8934 - mae: 2016.2925 - mse: 14635825.0000\n",
      "Epoch 45/1000\n",
      "2166/2166 [==============================] - 0s 149us/sample - loss: 13717183.6377 - mae: 1808.1184 - mse: 13717184.0000\n",
      "Epoch 46/1000\n",
      "2166/2166 [==============================] - 0s 144us/sample - loss: 12839168.1887 - mae: 1617.9193 - mse: 12839168.0000\n",
      "Epoch 47/1000\n",
      "2166/2166 [==============================] - 0s 209us/sample - loss: 14272521.6966 - mae: 1928.4960 - mse: 14272521.0000\n",
      "Epoch 48/1000\n",
      "2166/2166 [==============================] - 0s 196us/sample - loss: 16122670.1560 - mae: 2196.9297 - mse: 16122673.0000\n",
      "Epoch 49/1000\n",
      "2166/2166 [==============================] - 0s 180us/sample - loss: 12987327.6780 - mae: 1743.5652 - mse: 12987327.0000\n",
      "Epoch 50/1000\n",
      "2166/2166 [==============================] - 0s 160us/sample - loss: 15200419.6066 - mae: 2053.4116 - mse: 15200418.0000\n",
      "Epoch 51/1000\n",
      "2166/2166 [==============================] - 0s 126us/sample - loss: 13548156.7789 - mae: 1825.1511 - mse: 13548158.0000\n",
      "Epoch 52/1000\n",
      "2166/2166 [==============================] - 0s 182us/sample - loss: 14764571.2401 - mae: 2001.8759 - mse: 14764570.0000\n",
      "Epoch 53/1000\n",
      "2166/2166 [==============================] - 0s 138us/sample - loss: 14454325.2911 - mae: 1960.3539 - mse: 14454326.0000\n",
      "Epoch 54/1000\n",
      "2166/2166 [==============================] - 0s 172us/sample - loss: 12456761.7087 - mae: 1543.7595 - mse: 12456761.0000\n",
      "Epoch 55/1000\n",
      "2166/2166 [==============================] - 0s 196us/sample - loss: 13023879.4118 - mae: 1664.3506 - mse: 13023880.0000\n",
      "Epoch 56/1000\n",
      "2166/2166 [==============================] - 0s 157us/sample - loss: 13254475.4621 - mae: 1751.0059 - mse: 13254474.0000\n",
      "Epoch 57/1000\n",
      "2166/2166 [==============================] - 0s 127us/sample - loss: 12971012.4848 - mae: 1642.1285 - mse: 12971015.0000\n",
      "Epoch 58/1000\n",
      "2166/2166 [==============================] - 0s 140us/sample - loss: 20172466.8629 - mae: 2898.5190 - mse: 20172470.0000\n",
      "Epoch 59/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2166/2166 [==============================] - 0s 152us/sample - loss: 13221400.6676 - mae: 1768.7466 - mse: 13221403.0000\n",
      "Epoch 60/1000\n",
      "2166/2166 [==============================] - 0s 168us/sample - loss: 12860571.1884 - mae: 1621.2467 - mse: 12860572.0000\n",
      "Epoch 61/1000\n",
      "2166/2166 [==============================] - 0s 157us/sample - loss: 13624886.0175 - mae: 1783.2970 - mse: 13624887.0000\n",
      "Epoch 62/1000\n",
      "2166/2166 [==============================] - 0s 187us/sample - loss: 13706610.9584 - mae: 1891.7710 - mse: 13706613.0000\n",
      "Epoch 63/1000\n",
      "2166/2166 [==============================] - 0s 150us/sample - loss: 13800960.8204 - mae: 1941.9026 - mse: 13800961.0000\n",
      "Epoch 64/1000\n",
      "2166/2166 [==============================] - 0s 146us/sample - loss: 12864983.4977 - mae: 1684.4268 - mse: 12864986.0000\n",
      "Epoch 65/1000\n",
      "2166/2166 [==============================] - 0s 164us/sample - loss: 14149670.1297 - mae: 1980.8850 - mse: 14149667.0000\n",
      "Epoch 66/1000\n",
      "2166/2166 [==============================] - 0s 168us/sample - loss: 12954466.6349 - mae: 1745.7300 - mse: 12954466.0000\n",
      "Epoch 67/1000\n",
      "2166/2166 [==============================] - 0s 212us/sample - loss: 12692018.9972 - mae: 1657.7056 - mse: 12692020.0000\n",
      "Epoch 68/1000\n",
      "2166/2166 [==============================] - 0s 182us/sample - loss: 12518047.4584 - mae: 1585.5887 - mse: 12518046.0000\n",
      "Epoch 69/1000\n",
      "2166/2166 [==============================] - 0s 165us/sample - loss: 12375598.4617 - mae: 1558.8698 - mse: 12375600.0000\n",
      "Epoch 70/1000\n",
      "2166/2166 [==============================] - 0s 139us/sample - loss: 12686216.2816 - mae: 1677.4974 - mse: 12686218.0000\n",
      "Epoch 71/1000\n",
      "2166/2166 [==============================] - 0s 205us/sample - loss: 13888601.1256 - mae: 1957.1604 - mse: 13888603.0000\n",
      "Epoch 72/1000\n",
      "2166/2166 [==============================] - 0s 166us/sample - loss: 12840958.8989 - mae: 1705.2784 - mse: 12840957.0000\n",
      "Epoch 73/1000\n",
      "2166/2166 [==============================] - 0s 163us/sample - loss: 12381629.4460 - mae: 1589.0061 - mse: 12381630.0000\n",
      "Epoch 74/1000\n",
      "2166/2166 [==============================] - 0s 140us/sample - loss: 15351128.6417 - mae: 2150.2151 - mse: 15351128.0000\n",
      "Epoch 75/1000\n",
      "2166/2166 [==============================] - 0s 154us/sample - loss: 12513366.5720 - mae: 1619.8782 - mse: 12513369.0000\n",
      "Epoch 76/1000\n",
      "2166/2166 [==============================] - 0s 142us/sample - loss: 13891511.9612 - mae: 1843.3973 - mse: 13891512.0000\n",
      "Epoch 77/1000\n",
      "2166/2166 [==============================] - 0s 132us/sample - loss: 12802999.1348 - mae: 1702.3591 - mse: 12803001.0000\n",
      "Epoch 78/1000\n",
      "2166/2166 [==============================] - 0s 116us/sample - loss: 14935077.5993 - mae: 2071.4854 - mse: 14935078.0000\n",
      "Epoch 79/1000\n",
      "2166/2166 [==============================] - 0s 144us/sample - loss: 13716194.8680 - mae: 1866.9736 - mse: 13716194.0000\n",
      "Epoch 80/1000\n",
      "2166/2166 [==============================] - 1s 243us/sample - loss: 13574148.1145 - mae: 1906.1364 - mse: 13574147.0000\n",
      "Epoch 81/1000\n",
      "2166/2166 [==============================] - 1s 259us/sample - loss: 12547182.9455 - mae: 1606.4054 - mse: 12547183.0000\n",
      "Epoch 82/1000\n",
      "2166/2166 [==============================] - 0s 206us/sample - loss: 13474001.7932 - mae: 1811.4233 - mse: 13474000.0000\n",
      "Epoch 83/1000\n",
      "2166/2166 [==============================] - 1s 249us/sample - loss: 12740077.5023 - mae: 1651.4064 - mse: 12740076.0000\n",
      "Epoch 84/1000\n",
      "2166/2166 [==============================] - 0s 145us/sample - loss: 13713924.4071 - mae: 1754.0889 - mse: 13713923.0000\n",
      "Epoch 85/1000\n",
      "2166/2166 [==============================] - 0s 184us/sample - loss: 13396389.5679 - mae: 1848.3800 - mse: 13396392.0000\n",
      "Epoch 86/1000\n",
      "2166/2166 [==============================] - 0s 157us/sample - loss: 13141440.0491 - mae: 1764.0413 - mse: 13141441.0000\n",
      "Epoch 87/1000\n",
      "2166/2166 [==============================] - 0s 201us/sample - loss: 15780529.2393 - mae: 2315.0486 - mse: 15780532.0000\n",
      "Epoch 88/1000\n",
      "2166/2166 [==============================] - 0s 168us/sample - loss: 12613226.4229 - mae: 1523.2358 - mse: 12613225.0000\n",
      "Epoch 89/1000\n",
      "2166/2166 [==============================] - 0s 202us/sample - loss: 13468011.0937 - mae: 1811.6951 - mse: 13468010.0000\n",
      "Epoch 90/1000\n",
      "2166/2166 [==============================] - 0s 173us/sample - loss: 12052654.7438 - mae: 1569.7203 - mse: 12052653.0000\n",
      "Epoch 91/1000\n",
      "2166/2166 [==============================] - 0s 161us/sample - loss: 13423919.8430 - mae: 1864.6718 - mse: 13423920.0000\n",
      "Epoch 92/1000\n",
      "2166/2166 [==============================] - 0s 154us/sample - loss: 13340560.4146 - mae: 1846.2968 - mse: 13340559.0000\n",
      "Epoch 93/1000\n",
      "2166/2166 [==============================] - 1s 234us/sample - loss: 12804389.1514 - mae: 1660.2024 - mse: 12804387.0000\n",
      "Epoch 94/1000\n",
      "2166/2166 [==============================] - 0s 137us/sample - loss: 13335670.8952 - mae: 1743.6603 - mse: 13335671.0000\n",
      "Epoch 95/1000\n",
      "2166/2166 [==============================] - 0s 169us/sample - loss: 12785340.1265 - mae: 1728.3541 - mse: 12785339.0000\n",
      "Epoch 96/1000\n",
      "2166/2166 [==============================] - 0s 148us/sample - loss: 12285569.8684 - mae: 1546.7509 - mse: 12285570.0000\n",
      "Epoch 97/1000\n",
      "2166/2166 [==============================] - 0s 208us/sample - loss: 12955053.8886 - mae: 1654.9519 - mse: 12955057.0000\n",
      "Epoch 98/1000\n",
      "2166/2166 [==============================] - 0s 171us/sample - loss: 12428678.5046 - mae: 1577.1487 - mse: 12428678.0000\n",
      "Epoch 99/1000\n",
      "2166/2166 [==============================] - 0s 132us/sample - loss: 13946716.9007 - mae: 1928.7605 - mse: 13946718.0000\n",
      "Epoch 100/1000\n",
      "2166/2166 [==============================] - 0s 176us/sample - loss: 13991577.5854 - mae: 1878.3883 - mse: 13991577.0000\n",
      "Epoch 101/1000\n",
      "2166/2166 [==============================] - 0s 217us/sample - loss: 12470732.5584 - mae: 1588.2599 - mse: 12470732.0000\n",
      "Epoch 102/1000\n",
      "2166/2166 [==============================] - 0s 228us/sample - loss: 12293053.4192 - mae: 1576.5149 - mse: 12293053.0000\n",
      "Epoch 103/1000\n",
      "2166/2166 [==============================] - 1s 251us/sample - loss: 15663750.9464 - mae: 2257.8550 - mse: 15663754.0000\n",
      "Epoch 104/1000\n",
      "2166/2166 [==============================] - 0s 221us/sample - loss: 16144353.2098 - mae: 2219.3008 - mse: 16144352.0000\n",
      "Epoch 105/1000\n",
      "2166/2166 [==============================] - 0s 180us/sample - loss: 12888546.3437 - mae: 1677.7725 - mse: 12888546.0000\n",
      "Epoch 106/1000\n",
      "2166/2166 [==============================] - 0s 186us/sample - loss: 13447250.4063 - mae: 1843.8092 - mse: 13447249.0000\n",
      "Epoch 107/1000\n",
      "2166/2166 [==============================] - 0s 218us/sample - loss: 12035003.5140 - mae: 1484.4512 - mse: 12035002.0000\n",
      "Epoch 108/1000\n",
      "2166/2166 [==============================] - 1s 233us/sample - loss: 12605094.8153 - mae: 1568.3438 - mse: 12605094.0000\n",
      "Epoch 109/1000\n",
      "2166/2166 [==============================] - 0s 226us/sample - loss: 12113661.9215 - mae: 1499.1101 - mse: 12113663.0000\n",
      "Epoch 110/1000\n",
      "2166/2166 [==============================] - 1s 275us/sample - loss: 12627235.4124 - mae: 1686.3090 - mse: 12627234.0000\n",
      "Epoch 111/1000\n",
      "2166/2166 [==============================] - 0s 172us/sample - loss: 13119938.4236 - mae: 1726.7557 - mse: 13119939.0000\n",
      "Epoch 112/1000\n",
      "2166/2166 [==============================] - 0s 188us/sample - loss: 12750304.5664 - mae: 1660.8059 - mse: 12750307.0000\n",
      "Epoch 113/1000\n",
      "2166/2166 [==============================] - 0s 192us/sample - loss: 12302499.3047 - mae: 1563.9862 - mse: 12302501.0000\n",
      "Epoch 114/1000\n",
      "2166/2166 [==============================] - 0s 222us/sample - loss: 13045989.9197 - mae: 1748.2712 - mse: 13045990.0000\n",
      "Epoch 115/1000\n",
      "2166/2166 [==============================] - 0s 172us/sample - loss: 15819835.4730 - mae: 2279.2952 - mse: 15819839.0000 - loss: 23850406.3529 - mae: 2827.9480 - mse: 238\n",
      "Epoch 116/1000\n",
      "2166/2166 [==============================] - 0s 166us/sample - loss: 12376134.3467 - mae: 1670.6041 - mse: 12376134.0000\n",
      "Epoch 117/1000\n",
      "2166/2166 [==============================] - 1s 255us/sample - loss: 13091814.6777 - mae: 1821.8654 - mse: 13091814.0000\n",
      "Epoch 118/1000\n",
      "1536/2166 [====================>.........] - ETA: 0s - loss: 12198736.0332 - mae: 1561.9976 - mse: 12198739.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-979ea7ac1bc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mearly_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mae'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mearly_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_model_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf_model_2 = build_tf_model()\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor = 'mae', patience = 10)\n",
    "\n",
    "early_history = tf_model_2.fit(X_train, y_train, epochs = 1000, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
